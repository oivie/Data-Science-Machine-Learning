{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **author: Elena Pashkova**\n",
        "dataset: FashionMNIST\n",
        "\n",
        "**Objective:**\n",
        "*   Understand the basics of Recurrent Neural Networks (RNNs) and their application in deep learning.\n",
        "*   Practice building and training RNN models for real-world problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "3NWb4QCXCHl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding RNN Basics**\n",
        "**Basic Architecture of RNNs and How They Differ from Traditional Feedforward Neural Networks**\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are a type of neural network architecture designed to handle sequential data by maintaining a \"memory\" of previous inputs. Unlike traditional feedforward neural networks, which process inputs independently, RNNs have connections that allow information to persist, creating dependencies between inputs over time. In an RNN, the output from each step depends not only on the current input but also on the output from the previous step. This is achieved through a loop within the network that enables the model to pass information from one step of the sequence to the next.\n",
        "\n",
        "In a traditional feedforward neural network, information flows in one direction â€” from the input layer, through the hidden layers, to the output layer. Each input is processed independently, which makes it unsuitable for tasks where context from previous inputs is needed, such as language processing or time series prediction. RNNs, with their ability to process sequential data, are more effective in these cases.\n",
        "\n",
        "---\n",
        "\n",
        "**The Concept of \"Short-Term Memory\" in RNNs**\n",
        "\n",
        "The \"short-term memory\" in RNNs refers to the network's ability to retain information from previous time steps within a sequence. This memory allows RNNs to capture dependencies in data, such as the context of a word in a sentence based on prior words. However, this memory is inherently limited, as RNNs can struggle with maintaining information over long sequences. This issue is known as the \"vanishing gradient problem,\" where gradients become very small as they are backpropagated through time, leading to a loss of long-term information.\n",
        "\n",
        "Short-term memory makes RNNs suitable for tasks where recent past information is crucial, but they may struggle with longer dependencies. Variants like LSTMs (Long Short-Term Memory networks) and GRUs (Gated Recurrent Units) have been developed to improve the network's ability to maintain information over longer periods.\n",
        "\n",
        "---\n",
        "\n",
        "**Advantages and Disadvantages of Using RNNs**\n",
        "\n",
        "*Advantages:*\n",
        "\n",
        "*   Sequential Processing: RNNs are designed to handle sequential data, making them suitable for tasks like natural language processing and time series forecasting, where order and context matter.\n",
        "*   Temporal Dependencies: RNNs can capture dependencies between time steps in data, enabling them to understand relationships within a sequence (e.g., predicting the next word in a sentence based on previous words).\n",
        "\n",
        "\n",
        "*Disadvantages:*\n",
        "\n",
        "\n",
        "*   Vanishing Gradient Problem: RNNs can suffer from the vanishing gradient problem, which makes it difficult for them to learn long-term dependencies.\n",
        "*   High Computational Cost: RNNs are more computationally intensive than feedforward networks due to their recurrent nature, which requires sequential processing and makes parallelization challenging.\n",
        "\n",
        "\n",
        "These are key aspects to consider when using RNNs in different types of machine learning tasks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KXCIcbiOCY74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch Implementation **"
      ],
      "metadata": {
        "id": "MwJRSS-bD7bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "m-BDgC6ED_z5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Preprocess the Fashion-MNIST Dataset\n",
        "\n",
        "# Define transformations for the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] range\n",
        "])\n",
        "\n",
        "# Download and load the Fashion-MNIST dataset\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "YC7VAuZ-EH0P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Hyperparameters and Instantiate the Model\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 28          # Each row of pixels as one time step\n",
        "sequence_length = 28      # Number of rows\n",
        "hidden_size = 256         # Increased hidden size\n",
        "num_layers = 3            # Increased number of layers\n",
        "num_classes = 10\n",
        "learning_rate = 0.0005    # Reduced learning rate\n",
        "num_epochs = 15           # Increased number of epochs"
      ],
      "metadata": {
        "id": "t9MfUxbuEnTg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN Model\n",
        "\n",
        "# Define the updated RNN model with modified hidden size and number of layers\n",
        "class FashionMNISTRNN(nn.Module):\n",
        "    def __init__(self, input_size=28, hidden_size=256, num_layers=3, num_classes=10):\n",
        "        super(FashionMNISTRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Define the RNN layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        # Define a fully connected output layer\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden state\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward propagate RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "\n",
        "        # Get the last time step's output\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "hE5PeYwBEZ7r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer with updated hyperparameters\n",
        "model = FashionMNISTRNN(input_size, hidden_size, num_layers, num_classes).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "2VaYbI6GGLlX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "\n",
        "# Training loop with increased epochs\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Reshape images to (batch_size, sequence_length, input_size)\n",
        "        images = images.reshape(-1, sequence_length, input_size).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIm0I0ccEsQ9",
        "outputId": "99cb4758-b786-4b0c-b999-172e8ac5cc56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Step [100/938], Loss: 0.9122\n",
            "Epoch [1/15], Step [200/938], Loss: 1.1335\n",
            "Epoch [1/15], Step [300/938], Loss: 0.9104\n",
            "Epoch [1/15], Step [400/938], Loss: 0.6759\n",
            "Epoch [1/15], Step [500/938], Loss: 0.8442\n",
            "Epoch [1/15], Step [600/938], Loss: 0.8974\n",
            "Epoch [1/15], Step [700/938], Loss: 0.5176\n",
            "Epoch [1/15], Step [800/938], Loss: 0.7636\n",
            "Epoch [1/15], Step [900/938], Loss: 0.5517\n",
            "Epoch [2/15], Step [100/938], Loss: 0.5240\n",
            "Epoch [2/15], Step [200/938], Loss: 0.4474\n",
            "Epoch [2/15], Step [300/938], Loss: 0.5894\n",
            "Epoch [2/15], Step [400/938], Loss: 0.4304\n",
            "Epoch [2/15], Step [500/938], Loss: 0.5670\n",
            "Epoch [2/15], Step [600/938], Loss: 0.3353\n",
            "Epoch [2/15], Step [700/938], Loss: 0.4719\n",
            "Epoch [2/15], Step [800/938], Loss: 0.4875\n",
            "Epoch [2/15], Step [900/938], Loss: 0.5165\n",
            "Epoch [3/15], Step [100/938], Loss: 0.3071\n",
            "Epoch [3/15], Step [200/938], Loss: 0.4747\n",
            "Epoch [3/15], Step [300/938], Loss: 0.3406\n",
            "Epoch [3/15], Step [400/938], Loss: 0.4456\n",
            "Epoch [3/15], Step [500/938], Loss: 0.6209\n",
            "Epoch [3/15], Step [600/938], Loss: 0.3133\n",
            "Epoch [3/15], Step [700/938], Loss: 0.3957\n",
            "Epoch [3/15], Step [800/938], Loss: 0.7914\n",
            "Epoch [3/15], Step [900/938], Loss: 0.4684\n",
            "Epoch [4/15], Step [100/938], Loss: 0.5153\n",
            "Epoch [4/15], Step [200/938], Loss: 0.3990\n",
            "Epoch [4/15], Step [300/938], Loss: 0.5676\n",
            "Epoch [4/15], Step [400/938], Loss: 0.4429\n",
            "Epoch [4/15], Step [500/938], Loss: 0.4111\n",
            "Epoch [4/15], Step [600/938], Loss: 0.4852\n",
            "Epoch [4/15], Step [700/938], Loss: 0.4048\n",
            "Epoch [4/15], Step [800/938], Loss: 0.4706\n",
            "Epoch [4/15], Step [900/938], Loss: 0.4958\n",
            "Epoch [5/15], Step [100/938], Loss: 0.3088\n",
            "Epoch [5/15], Step [200/938], Loss: 0.3961\n",
            "Epoch [5/15], Step [300/938], Loss: 0.3696\n",
            "Epoch [5/15], Step [400/938], Loss: 0.3601\n",
            "Epoch [5/15], Step [500/938], Loss: 0.3832\n",
            "Epoch [5/15], Step [600/938], Loss: 0.6064\n",
            "Epoch [5/15], Step [700/938], Loss: 0.4451\n",
            "Epoch [5/15], Step [800/938], Loss: 0.5365\n",
            "Epoch [5/15], Step [900/938], Loss: 0.5884\n",
            "Epoch [6/15], Step [100/938], Loss: 0.6256\n",
            "Epoch [6/15], Step [200/938], Loss: 0.6803\n",
            "Epoch [6/15], Step [300/938], Loss: 0.5831\n",
            "Epoch [6/15], Step [400/938], Loss: 0.5161\n",
            "Epoch [6/15], Step [500/938], Loss: 0.5536\n",
            "Epoch [6/15], Step [600/938], Loss: 0.3979\n",
            "Epoch [6/15], Step [700/938], Loss: 0.5133\n",
            "Epoch [6/15], Step [800/938], Loss: 0.3419\n",
            "Epoch [6/15], Step [900/938], Loss: 0.4314\n",
            "Epoch [7/15], Step [100/938], Loss: 0.2493\n",
            "Epoch [7/15], Step [200/938], Loss: 0.4207\n",
            "Epoch [7/15], Step [300/938], Loss: 0.5886\n",
            "Epoch [7/15], Step [400/938], Loss: 0.3688\n",
            "Epoch [7/15], Step [500/938], Loss: 0.4059\n",
            "Epoch [7/15], Step [600/938], Loss: 0.5517\n",
            "Epoch [7/15], Step [700/938], Loss: 0.6754\n",
            "Epoch [7/15], Step [800/938], Loss: 0.2771\n",
            "Epoch [7/15], Step [900/938], Loss: 0.4312\n",
            "Epoch [8/15], Step [100/938], Loss: 0.4838\n",
            "Epoch [8/15], Step [200/938], Loss: 0.3407\n",
            "Epoch [8/15], Step [300/938], Loss: 0.2918\n",
            "Epoch [8/15], Step [400/938], Loss: 0.6116\n",
            "Epoch [8/15], Step [500/938], Loss: 0.5775\n",
            "Epoch [8/15], Step [600/938], Loss: 0.3528\n",
            "Epoch [8/15], Step [700/938], Loss: 0.4829\n",
            "Epoch [8/15], Step [800/938], Loss: 0.5014\n",
            "Epoch [8/15], Step [900/938], Loss: 0.3453\n",
            "Epoch [9/15], Step [100/938], Loss: 0.4379\n",
            "Epoch [9/15], Step [200/938], Loss: 0.4186\n",
            "Epoch [9/15], Step [300/938], Loss: 0.2917\n",
            "Epoch [9/15], Step [400/938], Loss: 0.4033\n",
            "Epoch [9/15], Step [500/938], Loss: 0.5982\n",
            "Epoch [9/15], Step [600/938], Loss: 0.4037\n",
            "Epoch [9/15], Step [700/938], Loss: 0.3777\n",
            "Epoch [9/15], Step [800/938], Loss: 0.1972\n",
            "Epoch [9/15], Step [900/938], Loss: 0.2975\n",
            "Epoch [10/15], Step [100/938], Loss: 0.2798\n",
            "Epoch [10/15], Step [200/938], Loss: 0.2864\n",
            "Epoch [10/15], Step [300/938], Loss: 0.5678\n",
            "Epoch [10/15], Step [400/938], Loss: 0.4040\n",
            "Epoch [10/15], Step [500/938], Loss: 0.2540\n",
            "Epoch [10/15], Step [600/938], Loss: 0.4532\n",
            "Epoch [10/15], Step [700/938], Loss: 0.3791\n",
            "Epoch [10/15], Step [800/938], Loss: 0.1877\n",
            "Epoch [10/15], Step [900/938], Loss: 0.4067\n",
            "Epoch [11/15], Step [100/938], Loss: 0.6582\n",
            "Epoch [11/15], Step [200/938], Loss: 0.5004\n",
            "Epoch [11/15], Step [300/938], Loss: 0.2129\n",
            "Epoch [11/15], Step [400/938], Loss: 0.2979\n",
            "Epoch [11/15], Step [500/938], Loss: 0.3544\n",
            "Epoch [11/15], Step [600/938], Loss: 0.3156\n",
            "Epoch [11/15], Step [700/938], Loss: 0.4562\n",
            "Epoch [11/15], Step [800/938], Loss: 0.3049\n",
            "Epoch [11/15], Step [900/938], Loss: 0.3679\n",
            "Epoch [12/15], Step [100/938], Loss: 0.4952\n",
            "Epoch [12/15], Step [200/938], Loss: 0.4624\n",
            "Epoch [12/15], Step [300/938], Loss: 0.3562\n",
            "Epoch [12/15], Step [400/938], Loss: 0.5313\n",
            "Epoch [12/15], Step [500/938], Loss: 0.3789\n",
            "Epoch [12/15], Step [600/938], Loss: 0.3607\n",
            "Epoch [12/15], Step [700/938], Loss: 0.3991\n",
            "Epoch [12/15], Step [800/938], Loss: 0.4323\n",
            "Epoch [12/15], Step [900/938], Loss: 0.5785\n",
            "Epoch [13/15], Step [100/938], Loss: 0.4515\n",
            "Epoch [13/15], Step [200/938], Loss: 0.6984\n",
            "Epoch [13/15], Step [300/938], Loss: 0.3948\n",
            "Epoch [13/15], Step [400/938], Loss: 0.2863\n",
            "Epoch [13/15], Step [500/938], Loss: 0.2708\n",
            "Epoch [13/15], Step [600/938], Loss: 0.4109\n",
            "Epoch [13/15], Step [700/938], Loss: 0.2186\n",
            "Epoch [13/15], Step [800/938], Loss: 0.4340\n",
            "Epoch [13/15], Step [900/938], Loss: 0.5037\n",
            "Epoch [14/15], Step [100/938], Loss: 0.3565\n",
            "Epoch [14/15], Step [200/938], Loss: 0.2263\n",
            "Epoch [14/15], Step [300/938], Loss: 0.3873\n",
            "Epoch [14/15], Step [400/938], Loss: 0.2446\n",
            "Epoch [14/15], Step [500/938], Loss: 0.3385\n",
            "Epoch [14/15], Step [600/938], Loss: 0.4592\n",
            "Epoch [14/15], Step [700/938], Loss: 0.2582\n",
            "Epoch [14/15], Step [800/938], Loss: 0.3778\n",
            "Epoch [14/15], Step [900/938], Loss: 0.3522\n",
            "Epoch [15/15], Step [100/938], Loss: 0.2678\n",
            "Epoch [15/15], Step [200/938], Loss: 0.3562\n",
            "Epoch [15/15], Step [300/938], Loss: 0.6974\n",
            "Epoch [15/15], Step [400/938], Loss: 0.3609\n",
            "Epoch [15/15], Step [500/938], Loss: 0.3609\n",
            "Epoch [15/15], Step [600/938], Loss: 0.2447\n",
            "Epoch [15/15], Step [700/938], Loss: 0.2277\n",
            "Epoch [15/15], Step [800/938], Loss: 0.4434\n",
            "Epoch [15/15], Step [900/938], Loss: 0.4392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, sequence_length, input_size).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy on the test set: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBrgdpQ4Ex2D",
        "outputId": "8a0ccb10-27f4-40fb-89f8-374d64f59429"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 85.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Short summaryy of improvements done to the model, between previous version and this:**\n",
        "\n",
        "**Before:**Initially, the RNN model had a hidden_size of 128, num_layers set to 2, a learning rate of 0.001, and was trained for only 5 epochs. The model's loss fluctuated considerably, and the accuracy on the test set was moderate, indicating some instability in training and limited learning capacity.\n",
        "\n",
        "**What Changed:** I increased the hidden_size to 256, num_layers to 3, reduced the learning rate to 0.0005, and extended the training to 15 epochs. These adjustments aimed to improve model capacity, stabilize training, and allow the model more time to converge.\n",
        "\n",
        "**Improvement**: The changes resulted in smoother loss reduction, better stability in training, and improved test accuracy, reaching 85.70%. The model now shows stronger generalization and a better ability to capture complex patterns in the Fashion-MNIST dataset.\n",
        "\n",
        "**Next Steps:**\n",
        "To further improve the model, you might consider:\n",
        "\n",
        "\n",
        "*   Trying LSTM or GRU Layers: Since they handle long-term dependencies better, they might further boost performance.\n",
        "*   Experimenting with Dropout: Adding dropout layers can prevent potential overfitting, especially with a larger model.\n",
        "*   Fine-Tuning Hyperparameters: Minor adjustments to learning rate, batch size, or hidden layer size could yield slight performance boosts.\n"
      ],
      "metadata": {
        "id": "mV5vd6RCINJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Additional Testing with Precision, Recall, and F1 Score**"
      ],
      "metadata": {
        "id": "ffflxe0yKcEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "Zs7va7h7KfhL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():  # Turn off gradients for testing\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, sequence_length, input_size).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Now calculate precision, recall, and F1 score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRTGe1MZKij7",
        "outputId": "d0a5043d-ff95-4d1f-e06c-10fb25e36996"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8633\n",
            "Recall: 0.8570\n",
            "F1 Score: 0.8582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieved an accuracy of 85.70% on the test set. Additional evaluation metrics indicate a precision of 86.33%, recall of 85.70%, and an F1 score of 85.82%. These metrics suggest that the model has a balanced performance in correctly identifying the Fashion-MNIST categories, with good precision and recall, which confirms its ability to generalize well to new data. Overall, the model demonstrates effective classification capabilities for this dataset.\n",
        "\n",
        "If further improvements are desired, fine-tuning hyperparameters or experimenting with different RNN architectures like LSTMs could be considered."
      ],
      "metadata": {
        "id": "gLqg0lcxK_F5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**\n"
      ],
      "metadata": {
        "id": "BEbvTOLxJDCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TAvnH3O4JCHK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of test images and labels\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)  # Use next(dataiter) directly\n",
        "images = images[:5].reshape(-1, sequence_length, input_size).to('cuda')\n",
        "labels = labels[:5].to('cuda')\n",
        "\n",
        "# Make predictions\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Plot results\n",
        "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
        "for i in range(5):\n",
        "    # Convert image from tensor to numpy and reshape for display\n",
        "    img = images[i].cpu().reshape(28, 28)\n",
        "    true_label = labels[i].item()\n",
        "    pred_label = predicted[i].item()\n",
        "\n",
        "    # Display image\n",
        "    axes[i].imshow(img, cmap='gray')\n",
        "\n",
        "    # Set title as \"Correct\" or \"Incorrect\" with labels\n",
        "    title_color = \"green\" if pred_label == true_label else \"red\"\n",
        "    axes[i].set_title(f\"Pred: {pred_label}, True: {true_label}\", color=title_color)\n",
        "    axes[i].axis('off')  # Hide axes for a cleaner look\n",
        "\n",
        "plt.suptitle(\"Model Predictions on Test Images\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "Wnc-jEaiFgBl",
        "outputId": "06dcab9a-26a8-4d94-8ecb-dc2f1a4e5b41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}